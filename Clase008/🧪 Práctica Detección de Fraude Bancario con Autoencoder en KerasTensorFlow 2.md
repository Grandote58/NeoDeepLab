![PRACTICA](D:\001_Uniminuto2025\005DeepLearning\Clase008\Recursos\assets\PRACTICA.png)

# **ðŸ§ª PrÃ¡ctica: DetecciÃ³n de Fraude Bancario con Autoencoder en Keras/TensorFlow 2**

## ðŸŽ¯ Objetivo general

DiseÃ±ar, entrenar y evaluar un **autoencoder denso** para la detecciÃ³n de fraudes bancarios, utilizando un dataset financiero abierto y aplicando un enfoque de **detecciÃ³n de anomalÃ­as** basado en error de reconstrucciÃ³n.

## ðŸŽ¯ Metas de aprendizaje

Al finalizar la prÃ¡ctica, el estudiante serÃ¡ capaz de:

1. Cargar y explorar un conjunto de datos abierto de transacciones bancarias (fraude con tarjeta de crÃ©dito).
2. Preprocesar variables numÃ©ricas para usarlas en un autoencoder (escalado, separaciÃ³n de clases, balanceo conceptual).
3. Implementar un **autoencoder en Keras/TensorFlow 2.x** para modelar el comportamiento normal de las transacciones.
4. Entrenar y validar el modelo, analizando curvas de pÃ©rdida y distribuciÃ³n del error de reconstrucciÃ³n.
5. Establecer un **umbral de anomalÃ­a** y evaluar el sistema con mÃ©tricas como matriz de confusiÃ³n, precision, recall y F1-score.
6. Interpretar los resultados y discutir ventajas, limitaciones y riesgos del enfoque.



> âœ… **InstrucciÃ³n clave para Colab**
>  Antes de empezar: ve a **Entorno de ejecuciÃ³n â†’ Cambiar tipo de entorno de ejecuciÃ³n â†’ Acelerador por hardware: GPU (opcional)** para acelerar el entrenamiento.

# **ðŸ§± SecciÃ³n 0 â€” ConfiguraciÃ³n inicial y librerÃ­as**

Crea una celda de cÃ³digo en Colab con lo siguiente:

```python
# ============================================
# SECCIÃ“N 0: IMPORTACIÃ“N DE LIBRERÃAS Y SETUP
# ============================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (confusion_matrix, classification_report,
                             precision_score, recall_score, f1_score,
                             roc_auc_score, roc_curve, precision_recall_curve)

import tensorflow as tf
from tensorflow.keras import layers, models

# Mostrar versiÃ³n de TensorFlow
print("VersiÃ³n de TensorFlow:", tf.__version__)

# Semillas para reproducibilidad
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
```

# **ðŸ“¥ SecciÃ³n 1 â€” Carga y visualizaciÃ³n del dataset (datos abiertos)**

Usaremos el dataset pÃºblico **Credit Card Fraud Detection** (Europa, 2013). Muchas copias estÃ¡n disponibles de forma abierta. En Colab podemos descargarlo desde un repositorio pÃºblico.

> ðŸ”Ž OpciÃ³n tÃ­pica: un repositorio pÃºblico de GitHub que contenga `creditcard.csv`.
>  (Al ejecutar en Colab, asegÃºrate de que la URL estÃ© accesible. Te dejo un ejemplo genÃ©rico con una URL de GitHub; si cambiara en el futuro, solo debes sustituirla por una URL pÃºblica de `creditcard.csv`.)

```python
# ============================================
# SECCIÃ“N 1: DESCARGA Y CARGA DEL DATASET
# ============================================

# EJEMPLO: descarga desde un repositorio pÃºblico (ajusta la URL si usas otra fuente)
!wget -q https://raw.githubusercontent.com/omdomg/creditcard-fraud-detection/master/creditcard.csv -O creditcard.csv

# Cargar el CSV
data = pd.read_csv("creditcard.csv")

# Mostrar dimensiones del dataset
print("Dimensiones del dataset:", data.shape)

# Primeras filas
display(data.head())

# InformaciÃ³n de tipos de datos
print("\nInformaciÃ³n del dataset:")
print(data.info())
```

# **ðŸ“Š SecciÃ³n 2 â€” ExploraciÃ³n inicial (EDA bÃ¡sica)**

### ðŸ”¹ 2.1 DistribuciÃ³n de la variable objetivo (fraude vs no fraude)

```python
# ============================================
# SECCIÃ“N 2: EXPLORACIÃ“N DE DATOS
# ============================================

# Ver distribuciÃ³n de la variable 'Class' (0 = no fraude, 1 = fraude)
class_counts = data['Class'].value_counts()
print("DistribuciÃ³n de clases:\n", class_counts)

# Porcentajes
fraud_percentage = class_counts[1] / class_counts.sum() * 100
print(f"\nPorcentaje de fraudes: {fraud_percentage:.4f}%")

# GrÃ¡fico de barras
plt.figure(figsize=(6,4))
class_counts.plot(kind='bar')
plt.title("DistribuciÃ³n de clases (0 = Normal, 1 = Fraude)")
plt.xlabel("Clase")
plt.ylabel("NÃºmero de transacciones")
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.show()
```

### ðŸ”¹ 2.2 EstadÃ­sticos descriptivos y distribuciÃ³n de algunos campos

```python
# DescripciÃ³n estadÃ­stica de las variables numÃ©ricas
display(data.describe().T.head(10))

# Histograma del monto de transacciÃ³n (Amount)
plt.figure(figsize=(6,4))
plt.hist(data['Amount'], bins=50)
plt.title("DistribuciÃ³n del monto de las transacciones")
plt.xlabel("Amount")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()

# Histograma de la variable 'Time'
plt.figure(figsize=(6,4))
plt.hist(data['Time'], bins=50)
plt.title("DistribuciÃ³n de la variable 'Time'")
plt.xlabel("Time (segundos desde primera transacciÃ³n)")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()
```

# **ðŸ§¼ SecciÃ³n 3 â€” Preprocesamiento de datos**

### Decisiones de diseÃ±o:

- Las variables `V1` a `V28` ya son componentes PCA anonimizados.
- Normalizaremos **Amount** y **Time**, y luego escalaremos todo el vector de caracterÃ­sticas.
- Usaremos solo variables numÃ©ricas para el autoencoder.

### ðŸ”¹ 3.1 SeparaciÃ³n de caracterÃ­sticas y etiqueta

```python
# ============================================
# SECCIÃ“N 3: PREPROCESAMIENTO
# ============================================

# Separar caracterÃ­sticas (X) y etiqueta (y)
X = data.drop('Class', axis=1)
y = data['Class']

print("Shape de X:", X.shape)
print("Shape de y:", y.shape)
```

### ðŸ”¹ 3.2 Escalado de variables (StandardScaler)

```python
# Escalar todas las caracterÃ­sticas con StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("X_scaled shape:", X_scaled.shape)

# Convertir a DataFrame para inspecciÃ³n
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

display(X_scaled_df.describe().T.head(10))
```

# **ðŸ§ª SecciÃ³n 4 â€” DivisiÃ³n normal vs fraude, y particiÃ³n train/test**

El autoencoder se entrenarÃ¡ **solo con transacciones normales (Class=0)**.

```python
# ============================================
# SECCIÃ“N 4: DIVISIÃ“N NORMAL / FRAUDE Y TRAIN/TEST
# ============================================

# Ãndices de normales y fraudes
normal_mask = (y == 0)
fraud_mask = (y == 1)

X_normal = X_scaled[normal_mask]
X_fraud = X_scaled[fraud_mask]

print("Transacciones normales:", X_normal.shape[0])
print("Transacciones fraude  :", X_fraud.shape[0])

# Dividimos normales en train y test
from sklearn.model_selection import train_test_split

X_train_normal, X_test_normal = train_test_split(
    X_normal, test_size=0.2, random_state=SEED
)

# Para evaluaciÃ³n, combinamos normales de test + todas las fraudes
X_test_combined = np.vstack([X_test_normal, X_fraud])
y_test_combined = np.hstack([np.zeros(len(X_test_normal)), np.ones(len(X_fraud))])

print("\nShape X_train_normal:", X_train_normal.shape)
print("Shape X_test_normal :", X_test_normal.shape)
print("Shape X_test_combined:", X_test_combined.shape)
print("Shape y_test_combined:", y_test_combined.shape)
```

### ðŸ”¹ 4.1 VisualizaciÃ³n simple del desbalance en test combinado

```python
unique_test, counts_test = np.unique(y_test_combined, return_counts=True)
print("\nDistribuciÃ³n en el conjunto de test combinado:")
for u, c in zip(unique_test, counts_test):
    print(f"Clase {u}: {c} transacciones")

plt.figure(figsize=(4,4))
plt.bar(['Normal', 'Fraude'], counts_test)
plt.title("DistribuciÃ³n en test combinado")
plt.ylabel("NÃºmero de transacciones")
plt.grid(axis='y')
plt.show()
```

# **ðŸ§  SecciÃ³n 5 â€” DefiniciÃ³n del Autoencoder en Keras/TensorFlow 2**

Usaremos un modelo fully-connected (denso) para datos tabulares.

### ðŸ”¹ 5.1 Arquitectura del autoencoder

```python
# ============================================
# SECCIÃ“N 5: DEFINICIÃ“N DEL AUTOENCODER
# ============================================

input_dim = X_train_normal.shape[1]
encoding_dim = 16  # dimensiÃ³n del espacio latente (bottleneck)

# DefiniciÃ³n con API funcional (mÃ¡s clara)
input_layer = layers.Input(shape=(input_dim,), name="input")

# Encoder
x = layers.Dense(64, activation='relu', name="enc_dense1")(input_layer)
x = layers.Dense(32, activation='relu', name="enc_dense2")(x)
latent = layers.Dense(encoding_dim, activation='relu', name="latent")(x)

# Decoder
x = layers.Dense(32, activation='relu', name="dec_dense1")(latent)
x = layers.Dense(64, activation='relu', name="dec_dense2")(x)
output_layer = layers.Dense(input_dim, activation='linear', name="output")(x)

autoencoder = models.Model(inputs=input_layer, outputs=output_layer, name="autoencoder_fraude")

autoencoder.summary()
```

# **âš™ï¸ SecciÃ³n 6 â€” CompilaciÃ³n y entrenamiento del Autoencoder**

Entrenaremos el modelo como una regresiÃ³n: entrada â‰ˆ salida, ambas son `X_train_normal`.

```python
# ============================================
# SECCIÃ“N 6: COMPILACIÃ“N Y ENTRENAMIENTO
# ============================================

autoencoder.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss='mse'   # pÃ©rdida de reconstrucciÃ³n
)

# Entrenamiento
EPOCHS = 30
BATCH_SIZE = 256

history = autoencoder.fit(
    X_train_normal, X_train_normal,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    shuffle=True,
    validation_split=0.1,
    verbose=1
)
```

### ðŸ”¹ 6.1 GrÃ¡ficas de pÃ©rdida de entrenamiento y validaciÃ³n

```python
plt.figure(figsize=(6,4))
plt.plot(history.history['loss'], label='PÃ©rdida de entrenamiento')
plt.plot(history.history['val_loss'], label='PÃ©rdida de validaciÃ³n')
plt.title("Curva de pÃ©rdida del Autoencoder")
plt.xlabel("Ã‰pocas")
plt.ylabel("Loss (MSE)")
plt.legend()
plt.grid(True)
plt.show()
```

> ðŸ’¡ **InterpretaciÃ³n:**
>
> - PÃ©rdida decreciente y estabilizada = entrenamiento razonable.
> - Si `val_loss` sube mientras `loss` baja â†’ posible sobreajuste.

------

# **ðŸ§¾ SecciÃ³n 7 â€” CÃ¡lculo del error de reconstrucciÃ³n**

Calculamos el error MSE de reconstrucciÃ³n en **todo el conjunto de test combinado** (normales + fraudes).

```python
# ============================================
# SECCIÃ“N 7: ERROR DE RECONSTRUCCIÃ“N EN TEST
# ============================================

# Obtener reconstrucciones
reconstructions = autoencoder.predict(X_test_combined)

# Error MSE por transacciÃ³n
mse = np.mean(np.power(X_test_combined - reconstructions, 2), axis=1)

print("Shape mse:", mse.shape)
print("Primeros 10 errores MSE:", mse[:10])
```

### ðŸ”¹ 7.1 DistribuciÃ³n del error de reconstrucciÃ³n

```python
plt.figure(figsize=(6,4))
plt.hist(mse, bins=50)
plt.title("DistribuciÃ³n del error de reconstrucciÃ³n (MSE) - Test combinado")
plt.xlabel("MSE")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()
```

### ðŸ”¹ 7.2 Comparar errores entre normales y fraudes

```python
# Separar errores para normales y fraudes
mse_normal = mse[y_test_combined == 0]
mse_fraud = mse[y_test_combined == 1]

print("MSE normal - media:", np.mean(mse_normal), "mediana:", np.median(mse_normal))
print("MSE fraude - media:", np.mean(mse_fraud), "mediana:", np.median(mse_fraud))

plt.figure(figsize=(6,4))
plt.hist(mse_normal, bins=50, alpha=0.7, label='Normal')
plt.hist(mse_fraud,  bins=50, alpha=0.7, label='Fraude')
plt.title("DistribuciÃ³n MSE: normales vs fraudes")
plt.xlabel("MSE")
plt.ylabel("Frecuencia")
plt.legend()
plt.grid(True)
plt.show()
```

> ðŸ”Ž Esperado: los fraudes tienden a tener errores mÃ¡s altos que las transacciones normales.

# **ðŸ” SecciÃ³n 8 â€” SelecciÃ³n de umbral de anomalÃ­a**

Elegiremos un umbral basado en el **percentil** de los errores sobre transacciones normales de test.

```python
# ============================================
# SECCIÃ“N 8: UMBRAL DE ANOMALÃA
# ============================================

# Umbral basado solo en errores de las normales
threshold = np.percentile(mse_normal, 95)  # p.ej. percentil 95

print("Umbral seleccionado (percentil 95 de normales):", threshold)
```

PodrÃ­as probar otros percentiles (97, 99) para ajustar la sensibilidad.

# **ðŸ§® SecciÃ³n 9 â€” ClasificaciÃ³n final y mÃ©tricas**

### ðŸ”¹ 9.1 ClasificaciÃ³n segÃºn el umbral

```python
# ============================================
# SECCIÃ“N 9: CLASIFICACIÃ“N Y MÃ‰TRICAS
# ============================================

# PredicciÃ³n: 1 = fraude si error >= umbral
y_pred = (mse >= threshold).astype(int)

print("Primeras 20 predicciones:", y_pred[:20])
print("Primeros 20 valores reales:", y_test_combined[:20])
```

### ðŸ”¹ 9.2 Matriz de confusiÃ³n y mÃ©tricas clÃ¡sicas

```python
cm = confusion_matrix(y_test_combined, y_pred)
print("Matriz de confusiÃ³n:\n", cm)

tn, fp, fn, tp = cm.ravel()
print(f"\nTN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

print("\nReporte de clasificaciÃ³n:")
print(classification_report(y_test_combined, y_pred, digits=4))

precision = precision_score(y_test_combined, y_pred)
recall = recall_score(y_test_combined, y_pred)
f1 = f1_score(y_test_combined, y_pred)

print(f"Precision: {precision:.4f}")
print(f"Recall   : {recall:.4f}")
print(f"F1-score : {f1:.4f}")
```

### ðŸ”¹ 9.3 ROC-AUC y curva ROC

```python
# ROC-AUC usando los errores como score (mayor error = mÃ¡s probable fraude)
roc_auc = roc_auc_score(y_test_combined, mse)
print("ROC-AUC (usando MSE como score):", roc_auc)

fpr, tpr, _ = roc_curve(y_test_combined, mse)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0,1], [0,1], 'k--', label="Random")
plt.title("Curva ROC - DetecciÃ³n de fraude con Autoencoder")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()
```

### ðŸ”¹ 9.4 Curva Precisionâ€“Recall

```python
precision_vals, recall_vals, _ = precision_recall_curve(y_test_combined, mse)

plt.figure(figsize=(6,4))
plt.plot(recall_vals, precision_vals)
plt.title("Curva Precision-Recall - DetecciÃ³n de fraude")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.grid(True)
plt.show()
```

![pie](D:\001_Uniminuto2025\005DeepLearning\Clase008\Recursos\assets\pie.png)

