![PRACTICA](D:\001_Uniminuto2025\IMAGENES\PRACTICA.png)

# **üß™ Denoising Autoencoder con Fashion-MNIST**

**‚ÄúEliminaci√≥n de ruido en im√°genes de Fashion-MNIST usando Denoising Autoencoders‚Äù**

# **üéØ Objetivo general**

Implementar, entrenar y evaluar un **Denoising Autoencoder convolucional** capaz de reconstruir im√°genes limpias de Fashion-MNIST a partir de versiones con ruido, analizando detalladamente cada etapa del proceso: exploraci√≥n de datos, generaci√≥n de ruido, preprocesamiento, entrenamiento, validaci√≥n y evaluaci√≥n cuantitativa y cualitativa.

# **üéØ Metas de aprendizaje**

Al finalizar la pr√°ctica, el estudiante ser√° capaz de:

1. Cargar y explorar el dataset abierto **Fashion-MNIST**.
2. Generar versiones ruidosas de las im√°genes mediante **ruido gaussiano** controlado.
3. Preprocesar las im√°genes y preparar pares `(ruidosa ‚Üí limpia)` para entrenar un **Denoising Autoencoder**.
4. Definir, entrenar y validar un modelo de autoencoder convolucional en Keras/TensorFlow.
5. Visualizar comparativamente im√°genes **originales**, **ruidosas** y **reconstruidas**.
6. Calcular m√©tricas de **error de reconstrucci√≥n** y analizar la distribuci√≥n del error.
7. Identificar consideraciones t√©cnicas clave en el dise√±o y entrenamiento de autoencoders para reconstrucci√≥n de im√°genes.

------

# **üß± SECCI√ìN 0 ‚Äì Importaci√≥n de librer√≠as y configuraci√≥n**

```python
# ============================================
# SECCI√ìN 0: IMPORTACI√ìN DE LIBRER√çAS
# ============================================

import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras import layers, models

# Versi√≥n de TensorFlow
print("Versi√≥n de TensorFlow:", tf.__version__)

# Fijar semillas para reproducibilidad b√°sica
SEED = 123
np.random.seed(SEED)
tf.random.set_seed(SEED)

# Comprobar si hay GPU disponible
gpus = tf.config.list_physical_devices('GPU')
print("Dispositivos GPU disponibles:", gpus)
```

# **üìä SECCI√ìN 1 ‚Äì Carga y exploraci√≥n del dataset Fashion-MNIST**

### üîπ 1.1 Cargar datos abiertos Fashion-MNIST

```python
# ============================================
# SECCI√ìN 1: CARGA DEL DATASET FASHION-MNIST
# ============================================

from tensorflow.keras.datasets import fashion_mnist

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

print("Forma de x_train:", x_train.shape)
print("Forma de y_train:", y_train.shape)
print("Forma de x_test :", x_test.shape)
print("Forma de y_test :", y_test.shape)
```

### üîπ 1.2 Mapeo de clases (informativo)

```python
# Mapeo de etiquetas a nombres de clases (solo informativo, el autoencoder no usa y)
class_names = [
    "T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", 
    "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"
]

# Mostrar algunos ejemplos con sus etiquetas
num_samples = 9
plt.figure(figsize=(6, 6))
for i in range(num_samples):
    plt.subplot(3, 3, i+1)
    plt.imshow(x_train[i], cmap="gray")
    plt.title(class_names[y_train[i]])
    plt.axis("off")

plt.suptitle("Ejemplos del conjunto Fashion-MNIST (train)", fontsize=14)
plt.tight_layout()
plt.show()
```

### üîπ 1.3 Distribuci√≥n de clases y valores de p√≠xel

```python
# Distribuci√≥n de etiquetas
unique, counts = np.unique(y_train, return_counts=True)
print("Distribuci√≥n de clases en y_train:")
for u, c in zip(unique, counts):
    print(f"{u} ({class_names[u]}): {c} im√°genes")

# Histograma de intensidades de p√≠xel (0-255)
plt.figure(figsize=(6, 4))
plt.hist(x_train.reshape(-1), bins=50)
plt.title("Distribuci√≥n de intensidades de p√≠xel (x_train)")
plt.xlabel("Valor de p√≠xel (0-255)")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()
```

# **üßº SECCI√ìN 2 ‚Äì Normalizaci√≥n y preparaci√≥n de datos**

### üîπ 2.1 Normalizar im√°genes y a√±adir canal

```python
# ============================================
# SECCI√ìN 2: PREPROCESAMIENTO
# ============================================

# Convertir a float32 y normalizar [0, 1]
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

print("Rango de x_train despu√©s de normalizar:",
      x_train.min(), "a", x_train.max())
print("Rango de x_test despu√©s de normalizar:",
      x_test.min(), "a", x_test.max())

# A√±adir dimensi√≥n de canal (gris -> 1 canal)
x_train = np.expand_dims(x_train, axis=-1)  # (N, 28, 28, 1)
x_test = np.expand_dims(x_test, axis=-1)

print("Nueva forma de x_train:", x_train.shape)
print("Nueva forma de x_test :", x_test.shape)
```

### üîπ 2.2 Visualizaci√≥n r√°pida post-normalizaci√≥n

```python
plt.figure(figsize=(6, 3))
for i in range(6):
    plt.subplot(2, 3, i+1)
    plt.imshow(x_train[i].squeeze(), cmap="gray")
    plt.title(f"{class_names[y_train[i]]}")
    plt.axis("off")

plt.suptitle("Muestras normalizadas de Fashion-MNIST", fontsize=14)
plt.tight_layout()
plt.show()
```

# **üå´Ô∏è SECCI√ìN 3 ‚Äì Generaci√≥n de im√°genes ruidosas (Denoising)**

Vamos a generar una versi√≥n **ruidosa** de las im√°genes agregando **ruido gaussiano** controlado.

### üîπ 3.1 Funci√≥n para a√±adir ruido gaussiano

```python
# ============================================
# SECCI√ìN 3: GENERACI√ìN DE DATOS RUIDOSOS
# ============================================

def add_gaussian_noise(images, mean=0.0, std=0.3):
    """
    A√±ade ruido gaussiano a un conjunto de im√°genes.
    - images: array de forma (N, H, W, C) con valores en [0, 1]
    - mean: media del ruido
    - std: desviaci√≥n est√°ndar del ruido
    
    Devuelve:
    - im√°genes con ruido, recortadas a [0, 1]
    """
    noise = np.random.normal(loc=mean, scale=std, size=images.shape)
    noisy_images = images + noise
    # Recortar para mantener dentro de [0, 1]
    noisy_images = np.clip(noisy_images, 0., 1.)
    return noisy_images

# Generar conjuntos ruidosos
x_train_noisy = add_gaussian_noise(x_train, mean=0.0, std=0.4)
x_test_noisy = add_gaussian_noise(x_test, mean=0.0, std=0.4)

print("Rango de x_train_noisy:", x_train_noisy.min(), "a", x_train_noisy.max())
print("Rango de x_test_noisy :", x_test_noisy.min(), "a", x_test_noisy.max())
```

### üîπ 3.2 Visualizar im√°genes limpias vs ruidosas

```python
num_show = 8
plt.figure(figsize=(16, 4))

for i in range(num_show):
    # Original
    ax = plt.subplot(2, num_show, i+1)
    plt.imshow(x_train[i].squeeze(), cmap="gray")
    plt.title("Original")
    plt.axis("off")

    # Ruidosa
    ax = plt.subplot(2, num_show, i+1+num_show)
    plt.imshow(x_train_noisy[i].squeeze(), cmap="gray")
    plt.title("Ruidosa")
    plt.axis("off")

plt.suptitle("Comparaci√≥n de im√°genes originales vs ruidosas", fontsize=16)
plt.tight_layout()
plt.show()
```

### üîπ 3.3 Histograma de intensidades con ruido

```python
plt.figure(figsize=(6, 4))
plt.hist(x_train_noisy.reshape(-1), bins=50)
plt.title("Distribuci√≥n de intensidades con ruido (x_train_noisy)")
plt.xlabel("Valor de p√≠xel (0-1)")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()
```

> üîé **Reflexi√≥n**: Observa c√≥mo el ruido ensancha la distribuci√≥n de intensidades y hace las im√°genes visualmente m√°s dif√≠ciles de interpretar.

# **üß™ SECCI√ìN 4 ‚Äì Divisi√≥n en entrenamiento y validaci√≥n**

```python
# ============================================
# SECCI√ìN 4: SPLIT TRAIN / VALIDATION
# ============================================

val_fraction = 0.1
val_size = int(len(x_train) * val_fraction)

x_val_clean = x_train[:val_size]
x_val_noisy = x_train_noisy[:val_size]

x_train_clean = x_train[val_size:]
x_train_noisy_sub = x_train_noisy[val_size:]

print("x_train_clean     :", x_train_clean.shape)
print("x_train_noisy_sub :", x_train_noisy_sub.shape)
print("x_val_clean       :", x_val_clean.shape)
print("x_val_noisy       :", x_val_noisy.shape)
```

# **üß† SECCI√ìN 5 ‚Äì Definici√≥n del Denoising Autoencoder Convolucional**

Arquitectura general:

- Entrada: imagen **ruidosa** (28x28x1).
- Salida: imagen **limpia** (28x28x1).
- P√©rdida: distancia entre salida reconstruida y original limpia.

```python
# ============================================
# SECCI√ìN 5: DEFINICI√ìN DEL DENOISING AUTOENCODER
# ============================================

input_shape = (28, 28, 1)

denoise_inputs = layers.Input(shape=input_shape, name="denoise_input")

# Encoder
x = layers.Conv2D(32, (3,3), activation="relu", padding="same", name="enc_conv1")(denoise_inputs)
x = layers.MaxPooling2D((2,2), padding="same", name="enc_pool1")(x)

x = layers.Conv2D(64, (3,3), activation="relu", padding="same", name="enc_conv2")(x)
encoded = layers.MaxPooling2D((2,2), padding="same", name="enc_pool2")(x)

print("Forma del espacio latente (encoded):", encoded.shape)

# Decoder
x = layers.Conv2D(64, (3,3), activation="relu", padding="same", name="dec_conv1")(encoded)
x = layers.UpSampling2D((2,2), name="dec_up1")(x)

x = layers.Conv2D(32, (3,3), activation="relu", padding="same", name="dec_conv2")(x)
x = layers.UpSampling2D((2,2), name="dec_up2")(x)

denoise_outputs = layers.Conv2D(
    1, (3,3), activation="sigmoid", padding="same", name="dec_output"
)(x)

denoising_autoencoder = models.Model(
    denoise_inputs, denoise_outputs, name="denoising_autoencoder"
)

denoising_autoencoder.summary()
```

> ###### **‚ö†Ô∏è Advertencia t√©cnica:**
>
> - Usamos `sigmoid` como activaci√≥n final porque los p√≠xeles est√°n en [0, 1].
> - El modelo es undercomplete (reduce resoluci√≥n a 7x7x64) para obligar a aprender caracter√≠sticas robustas.

# **‚öôÔ∏è SECCI√ìN 6 ‚Äì Compilaci√≥n y entrenamiento**

```python
# ============================================
# SECCI√ìN 6: COMPILACI√ìN Y ENTRENAMIENTO
# ============================================

denoising_autoencoder.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss="binary_crossentropy"
)

epochs = 20
batch_size = 256

history = denoising_autoencoder.fit(
    x_train_noisy_sub, x_train_clean,
    epochs=epochs,
    batch_size=batch_size,
    shuffle=True,
    validation_data=(x_val_noisy, x_val_clean)
)
```

### üîπ 6.1 Curvas de p√©rdida (train vs val)

```python
plt.figure(figsize=(6, 4))
plt.plot(history.history["loss"], label="P√©rdida de entrenamiento")
plt.plot(history.history["val_loss"], label="P√©rdida de validaci√≥n")
plt.title("Curvas de p√©rdida (Denoising Autoencoder)")
plt.xlabel("√âpoca")
plt.ylabel("P√©rdida (binary_crossentropy)")
plt.legend()
plt.grid(True)
plt.show()
```

> üí° Si `val_loss` empieza a subir mientras `loss` baja, puede indicarse sobreajuste ‚Üí puedes reducir epochs, a√±adir regularizaci√≥n, etc.

# **üßæ SECCI√ìN 7 ‚Äì Evaluaci√≥n cualitativa: comparaci√≥n visual**

##### Compararemos tres versiones:

1. Imagen limpia (ground truth).
2. Imagen ruidosa de entrada.
3. Imagen reconstruida (denoised).

```python
# ============================================
# SECCI√ìN 7: EVALUACI√ìN CUALITATIVA
# ============================================

# Obtener reconstrucciones para el conjunto de test
x_test_denoised = denoising_autoencoder.predict(x_test_noisy)

num_images = 10
plt.figure(figsize=(18, 6))

for i in range(num_images):
    # Fila 1: Limpia original
    ax = plt.subplot(3, num_images, i + 1)
    plt.imshow(x_test[i].squeeze(), cmap="gray")
    plt.title("Limpia")
    plt.axis("off")
    
    # Fila 2: Ruidosa
    ax = plt.subplot(3, num_images, i + 1 + num_images)
    plt.imshow(x_test_noisy[i].squeeze(), cmap="gray")
    plt.title("Ruidosa")
    plt.axis("off")
    
    # Fila 3: Reconstruida
    ax = plt.subplot(3, num_images, i + 1 + 2*num_images)
    plt.imshow(x_test_denoised[i].squeeze(), cmap="gray")
    plt.title("Denoised")
    plt.axis("off")

plt.suptitle("Comparaci√≥n Limpia vs Ruidosa vs Reconstruida (Denoising AE)", fontsize=16)
plt.tight_layout()
plt.show()
```

> ##### üéØ Discusi√≥n:
>
> - ¬øQu√© detalles se recuperan bien?
> - ¬øQu√© tipo de ruido persiste?
> - ¬øSe observa suavizado excesivo (blur)?

# **üìè SECCI√ìN 8 ‚Äì Evaluaci√≥n cuantitativa: error de reconstrucci√≥n**

Usaremos **MSE** por imagen como un indicador de calidad de reconstrucci√≥n.

```python
# ============================================
# SECCI√ìN 8: EVALUACI√ìN CUANTITATIVA (MSE)
# ============================================

from sklearn.metrics import mean_squared_error

# Aplanar im√°genes para c√°lculo de MSE por muestra
x_test_clean_flat = x_test.reshape((len(x_test), -1))
x_test_denoised_flat = x_test_denoised.reshape((len(x_test_denoised), -1))

mse_per_image = np.mean(
    np.power(x_test_clean_flat - x_test_denoised_flat, 2), axis=1
)

print("Forma de mse_per_image:", mse_per_image.shape)
print("Primeros 10 valores de MSE:", mse_per_image[:10])

print("\nEstad√≠sticas del MSE:")
print("M√≠nimo :", mse_per_image.min())
print("M√°ximo :", mse_per_image.max())
print("Media  :", mse_per_image.mean())
print("Mediana:", np.median(mse_per_image))
```

### üîπ 8.1 Histograma del MSE

```python
plt.figure(figsize=(6, 4))
plt.hist(mse_per_image, bins=50)
plt.title("Distribuci√≥n del error de reconstrucci√≥n (MSE) en test")
plt.xlabel("MSE por imagen")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()
```

> üåê En aplicaciones reales, im√°genes con MSE inusualmente alto podr√≠an considerarse **an√≥malas** (por ejemplo, defectos de fabricaci√≥n, im√°genes de otra clase, etc.).

# **üß© SECCI√ìN 9 ‚Äì Consideraciones y advertencias t√©cnicas**

Incluye estas reflexiones como celdas de texto en Colab:

```python
### Consideraciones y advertencias t√©cnicas

- **Selecci√≥n de ruido**:  
  - El tipo y la intensidad del ruido durante el entrenamiento deben parecerse al ruido real del problema.
  - Demasiado poco ruido ‚Üí el modelo no se vuelve robusto.
  - Demasiado ruido ‚Üí la reconstrucci√≥n se vuelve muy dif√≠cil.

- **Capacidad del modelo**:  
  - M√°s capas y filtros permiten mayor capacidad, pero aumentan costo computacional y riesgo de sobreajuste.

- **Tama√±o del espacio latente**:  
  - En Denoising AE, un espacio latente razonablemente comprimido fuerza al modelo a aprender patrones robustos, no a copiar el ruido.

- **M√©tricas adicionales**:  
  - Podr√≠amos usar PSNR (Peak Signal-to-Noise Ratio) adem√°s del MSE, y m√©tricas perceptuales si se trabaja con im√°genes complejas.

- **Generalizaci√≥n**:  
  - Probar con datasets distintos y tipos de ruido (poisson, speckle, blur) asegura que el autoencoder no se limite a un solo escenario.
```

# **‚úÖ RESUMEN DE ESTA SEGUNDA PR√ÅCTICA**

En esta pr√°ctica has:

- Trabajado con **Fashion-MNIST**, un dataset abierto de im√°genes de moda.
- Generado versiones ruidosas de las im√°genes usando **ruido gaussiano**.
- Dise√±ado y entrenado un **Denoising Autoencoder convolucional**.
- Visualizado comparativamente im√°genes limpias, ruidosas y reconstruidas.
- Calculado y analizado la distribuci√≥n del **MSE por imagen**.
- Reflexionado sobre consideraciones pr√°cticas en el uso de autoencoders para **reconstrucci√≥n y limpieza de im√°genes**.



![pie](D:\001_Uniminuto2025\IMAGENES\pie.png)