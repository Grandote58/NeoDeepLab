

![p1](https://github.com/Grandote58/NeoDeepLab/blob/main/Clase007/assets/PRACTICA.png)

# **üß™ Autoencoders para la Reconstrucci√≥n de Im√°genes**

**‚ÄúReconstrucci√≥n de Im√°genes con Autoencoders Convolucionales en Deep Learning‚Äù**

## üéØ Objetivo general

Dise√±ar, entrenar y evaluar un **autoencoder convolucional** para la reconstrucci√≥n de im√°genes, utilizando un conjunto de datos abierto, analizando cada etapa del proceso (exploraci√≥n, preprocesamiento, entrenamiento, validaci√≥n y evaluaci√≥n).

## üéØ Metas de aprendizaje

Al finalizar esta pr√°ctica el estudiante ser√° capaz de:

1. **Cargar y explorar** un dataset de im√°genes de acceso abierto (MNIST).
2. **Preprocesar y normalizar** im√°genes para usarlas en un autoencoder convolucional.
3. **Implementar en Keras/TensorFlow** la arquitectura de un autoencoder para reconstrucci√≥n de im√°genes.
4. **Entrenar y validar** el modelo, analizando las curvas de p√©rdida.
5. **Evaluar la calidad de la reconstrucci√≥n** tanto cualitativamente (visualmente) como cuantitativamente (errores de reconstrucci√≥n).
6. **Interpretar el espacio latente** como representaci√≥n comprimida de las im√°genes.

## üîß Instrucciones iniciales para Google Colab

> En Colab, ve a:
>  **Entorno de ejecuci√≥n ‚Üí Cambiar tipo de entorno de ejecuci√≥n ‚Üí Acelerador por hardware: GPU**
>  y selecciona **GPU** para acelerar el entrenamiento.

# **üß± Secci√≥n 0 ‚Äî Importaci√≥n de librer√≠as y configuraci√≥n global**

Crea una celda de c√≥digo con lo siguiente:

```python
# ============================================
# SECCI√ìN 0: IMPORTACI√ìN DE LIBRER√çAS
# ============================================

import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras import layers, models

# Comprobar versi√≥n de TensorFlow
print("Versi√≥n de TensorFlow:", tf.__version__)

# Configurar un seed para reproducibilidad b√°sica
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

# Comprobar si hay GPU disponible
device_name = tf.config.list_physical_devices('GPU')
print("Dispositivos GPU disponibles:", device_name)
```

# **üìä Secci√≥n 1 ‚Äî Carga y exploraci√≥n del conjunto de datos (datos abiertos)**

Usaremos **MNIST**, un dataset abierto de d√≠gitos manuscritos (28x28, escala de grises).

### üîπ 1.1 Carga de datos

```python
# ============================================
# SECCI√ìN 1: CARGA DEL DATASET (MNIST)
# ============================================

# MNIST viene incluido en tf.keras.datasets y es de acceso abierto
from tensorflow.keras.datasets import mnist

# Cargar datos: (x_train, y_train), (x_test, y_test)
(x_train, y_train), (x_test, y_test) = mnist.load_data()

print("Forma de x_train:", x_train.shape)
print("Forma de y_train:", y_train.shape)
print("Forma de x_test :", x_test.shape)
print("Forma de y_test :", y_test.shape)
```

### üîπ 1.2 Exploraci√≥n b√°sica de datos

```python
# Mostrar algunos ejemplos de im√°genes y sus etiquetas originales
num_samples = 9
plt.figure(figsize=(6, 6))

for i in range(num_samples):
    plt.subplot(3, 3, i+1)
    plt.imshow(x_train[i], cmap="gray")
    plt.title(f"Etiqueta: {y_train[i]}")
    plt.axis("off")

plt.suptitle("Ejemplos de im√°genes del conjunto de entrenamiento (MNIST)", fontsize=14)
plt.tight_layout()
plt.show()
```

### üîπ 1.3 Distribuci√≥n de etiquetas y valores de p√≠xel

```python
# Distribuci√≥n de clases (aunque no se usen para el autoencoder, sirven para explorar)
unique, counts = np.unique(y_train, return_counts=True)
print("Distribuci√≥n de clases en y_train:")
for u, c in zip(unique, counts):
    print(f"D√≠gito {u}: {c} im√°genes")

# Graficar histograma de intensidades de p√≠xel
plt.figure(figsize=(6, 4))
plt.hist(x_train.reshape(-1), bins=50)
plt.title("Distribuci√≥n de valores de p√≠xel en x_train (0-255)")
plt.xlabel("Intensidad de p√≠xel")
plt.ylabel("Frecuencia")
plt.show()
```

# **üßº Secci√≥n 2 ‚Äî Preprocesamiento de datos**

### Pasos clave:

- Normalizar intensidades a rango [0, 1].
- A√±adir dimensi√≥n de canal: (28, 28, 1) para usar capas convolucionales.
- Dividir conjunto de validaci√≥n desde el train (opcional pero recomendado).

```python
# ============================================
# SECCI√ìN 2: PREPROCESAMIENTO
# ============================================

# Convertir a float32 y normalizar en el rango [0, 1]
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

print("Rango de valores despu√©s de normalizar:")
print("x_train min:", x_train.min(), "max:", x_train.max())
print("x_test  min:", x_test.min(), "max:", x_test.max())

# A√±adir dimensi√≥n de canal (canal √∫nico para escala de grises)
x_train = np.expand_dims(x_train, axis=-1)  # (num_samples, 28, 28, 1)
x_test = np.expand_dims(x_test, axis=-1)

print("Nueva forma de x_train:", x_train.shape)
print("Nueva forma de x_test :", x_test.shape)

# Crear subconjunto de validaci√≥n a partir de entrenamiento (por ejemplo, 10%)
val_fraction = 0.1
val_size = int(len(x_train) * val_fraction)

x_val = x_train[:val_size]
x_train_sub = x_train[val_size:]

print("Forma de x_train_sub:", x_train_sub.shape)
print("Forma de x_val      :", x_val.shape)
```

### üîπ 2.1 Visualizaci√≥n post-preprocesamiento

```python
# Verificar que las im√°genes siguen correctas tras el preprocesamiento
plt.figure(figsize=(6, 3))

for i in range(6):
    plt.subplot(2, 3, i+1)
    plt.imshow(x_train_sub[i].squeeze(), cmap="gray")
    plt.title(f"M√≠n: {x_train_sub[i].min():.2f} M√°x: {x_train_sub[i].max():.2f}")
    plt.axis("off")

plt.suptitle("Muestras tras normalizaci√≥n [0, 1]", fontsize=14)
plt.tight_layout()
plt.show()
```

# **üß† Secci√≥n 3 ‚Äî Definici√≥n de la arquitectura del Autoencoder Convolucional**

Dise√±aremos un **autoencoder convolucional undercomplete**:

- **Encoder**:
  - Conv2D ‚Üí ReLU ‚Üí MaxPooling
  - Conv2D ‚Üí ReLU ‚Üí MaxPooling
- **Latent**:
  - Mapa de activaci√≥n comprimido (por ejemplo 7x7x32).
- **Decoder**:
  - Conv2D ‚Üí ReLU ‚Üí UpSampling
  - Conv2D ‚Üí ReLU ‚Üí UpSampling
  - Conv2D (1 canal, activaci√≥n sigmoide) ‚Üí imagen reconstruida.

```python
# ============================================
# SECCI√ìN 3: DEFINICI√ìN DEL AUTOENCODER
# ============================================

input_shape = (28, 28, 1)

# Definici√≥n del modelo encoder
encoder_inputs = layers.Input(shape=input_shape, name="encoder_input")

# Bloque de convoluci√≥n 1
x = layers.Conv2D(
    filters=32, 
    kernel_size=(3, 3), 
    activation="relu", 
    padding="same",
    name="enc_conv1"
)(encoder_inputs)
x = layers.MaxPooling2D((2, 2), padding="same", name="enc_pool1")(x)

# Bloque de convoluci√≥n 2
x = layers.Conv2D(
    filters=64,
    kernel_size=(3, 3),
    activation="relu",
    padding="same",
    name="enc_conv2"
)(x)
encoded = layers.MaxPooling2D((2, 2), padding="same", name="enc_pool2")(x)

# encoded es el espacio latente en forma de mapa de caracter√≠sticas
print("Forma del espacio latente (encoded):", encoded.shape)

# Definici√≥n del decoder (sim√©trico aproximado)
x = layers.Conv2D(
    filters=64,
    kernel_size=(3, 3),
    activation="relu",
    padding="same",
    name="dec_conv1"
)(encoded)
x = layers.UpSampling2D((2, 2), name="dec_upsample1")(x)

x = layers.Conv2D(
    filters=32,
    kernel_size=(3, 3),
    activation="relu",
    padding="same",
    name="dec_conv2"
)(x)
x = layers.UpSampling2D((2, 2), name="dec_upsample2")(x)

decoder_outputs = layers.Conv2D(
    filters=1,
    kernel_size=(3, 3),
    activation="sigmoid",  # para salida en [0, 1]
    padding="same",
    name="dec_conv_output"
)(x)

# Autoencoder completo: entrada -> salida reconstruida
autoencoder = models.Model(encoder_inputs, decoder_outputs, name="conv_autoencoder")

autoencoder.summary()
```

# **‚öôÔ∏è Secci√≥n 4 ‚Äî Compilaci√≥n y entrenamiento del modelo**

Usaremos:

- Optimizador: **Adam**
- P√©rdida: **binary_crossentropy** (adecuada para im√°genes normalizadas en [0, 1])

```python
# ============================================
# SECCI√ìN 4: COMPILACI√ìN Y ENTRENAMIENTO
# ============================================

autoencoder.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss="binary_crossentropy"
)

# Entrenamiento
epochs = 15
batch_size = 256

history = autoencoder.fit(
    x_train_sub, x_train_sub,
    epochs=epochs,
    batch_size=batch_size,
    shuffle=True,
    validation_data=(x_val, x_val)
)
```

### üîπ 4.1 Visualizaci√≥n de curvas de entrenamiento y validaci√≥n

```
# Graficar la funci√≥n de p√©rdida (loss) de entrenamiento y validaci√≥n

plt.figure(figsize=(6, 4))
plt.plot(history.history["loss"], label="P√©rdida de entrenamiento")
plt.plot(history.history["val_loss"], label="P√©rdida de validaci√≥n")
plt.title("Curvas de p√©rdida (autoencoder)")
plt.xlabel("√âpocas")
plt.ylabel("P√©rdida (binary_crossentropy)")
plt.legend()
plt.grid(True)
plt.show()
```

> **Interpretaci√≥n:**
>
> - Curvas que disminuyen y se estabilizan sugieren un entrenamiento adecuado.
> - Si la p√©rdida de validaci√≥n sube mientras la de entrenamiento baja, puede haber sobreajuste.

# **üß™ Secci√≥n 5 ‚Äî Evaluaci√≥n cualitativa: visualizaci√≥n de reconstrucciones**

Probaremos el modelo en el conjunto de prueba (**x_test**).

```python
# ============================================
# SECCI√ìN 5: EVALUACI√ìN CUALITATIVA
# ============================================

# Obtener reconstrucciones del conjunto de test
decoded_imgs = autoencoder.predict(x_test)

# Visualizar algunas im√°genes originales vs reconstruidas
num_images = 10
plt.figure(figsize=(20, 4))

for i in range(num_images):
    # Im√°genes originales
    ax = plt.subplot(2, num_images, i + 1)
    plt.imshow(x_test[i].squeeze(), cmap="gray")
    plt.title("Original")
    plt.axis("off")

    # Im√°genes reconstruidas
    ax = plt.subplot(2, num_images, i + 1 + num_images)
    plt.imshow(decoded_imgs[i].squeeze(), cmap="gray")
    plt.title("Reconstruida")
    plt.axis("off")

plt.suptitle("Comparaci√≥n: Original vs Reconstruida (Autoencoder)", fontsize=16)
plt.tight_layout()
plt.show()
```

> Aqu√≠ puedes comentar visualmente:
>
> - ¬øSe conservan los contornos?
> - ¬øQu√© detalles se pierden?
> - ¬øHay signos de sobre-suavizado (blurring)?

# **üìè Secci√≥n 6 ‚Äî Evaluaci√≥n cuantitativa: error de reconstrucci√≥n**

Calcularemos el **error cuadr√°tico medio (MSE)** por imagen y analizaremos su distribuci√≥n.

```python
# ============================================
# SECCI√ìN 6: EVALUACI√ìN CUANTITATIVA
# ============================================

from sklearn.metrics import mean_squared_error

# Flatten para calcular el MSE por muestra (imagen)
x_test_flat = x_test.reshape((len(x_test), -1))
decoded_flat = decoded_imgs.reshape((len(decoded_imgs), -1))

# Calcular MSE por imagen
mse_per_image = np.mean(np.power(x_test_flat - decoded_flat, 2), axis=1)

print("Forma de mse_per_image:", mse_per_image.shape)
print("Ejemplos de MSE por imagen:", mse_per_image[:10])

# Estad√≠sticas descriptivas
print("\nEstad√≠sticas del error de reconstrucci√≥n (MSE):")
print("M√≠nimo:", np.min(mse_per_image))
print("M√°ximo:", np.max(mse_per_image))
print("Media :", np.mean(mse_per_image))
print("Mediana:", np.median(mse_per_image))
```

### üîπ 6.1 Histograma de errores de reconstrucci√≥n

```python
plt.figure(figsize=(6, 4))
plt.hist(mse_per_image, bins=50)
plt.title("Distribuci√≥n del error de reconstrucci√≥n (MSE) en el conjunto de test")
plt.xlabel("MSE por imagen")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()
```

> Este histograma te ayuda a ver:
>
> - ¬øLa mayor√≠a de las im√°genes se reconstruyen con error bajo?
> - ¬øHay colas largas que podr√≠an interpretarse como ‚Äúanomal√≠as‚Äù en una aplicaci√≥n de detecci√≥n de anomal√≠as?

# **üîç Secci√≥n 7 ‚Äî An√°lisis del espacio latente (opcional avanzado)**

Podemos extraer solo el **encoder** para obtener el espacio latente de las im√°genes.

```python
# ============================================
# SECCI√ìN 7: AN√ÅLISIS DEL ESPACIO LATENTE (OPCIONAL)
# ============================================

# Definimos un modelo encoder que termina en 'encoded'
encoder = models.Model(inputs=encoder_inputs, outputs=encoded, name="encoder_model")
encoder.summary()

# Obtenemos representaciones latentes de algunas im√°genes de test
latent_representations = encoder.predict(x_test[:1000])  # por ejemplo, 1000 im√°genes
print("Forma de latent_representations:", latent_representations.shape)

# Convertir a 2D para visualizaci√≥n (promediando canales y aplanando algo)
latent_flat = latent_representations.reshape((latent_representations.shape[0], -1))
print("Forma de latent_flat:", latent_flat.shape)
```

Puedes posteriormente usar **PCA o t-SNE** para visualizar, pero eso ya ser√≠a extensi√≥n.

## ‚ö†Ô∏è Advertencias t√©cnicas y buenas pr√°cticas

1. ##### **Normalizaci√≥n**:

    Aseg√∫rate de que las im√°genes est√©n normalizadas entre 0 y 1 cuando uses `sigmoid` como activaci√≥n de salida y `binary_crossentropy` como p√©rdida.

2. ##### **Tama√±o del espacio latente**:

   - Muy peque√±o ‚Üí p√©rdida de detalles, mala reconstrucci√≥n.
   - Muy grande ‚Üí poca compresi√≥n, riesgo de memorizar.

3. ##### **Capacidad del modelo**:

    Ajusta el n√∫mero de filtros y la profundidad del encoder/decoder seg√∫n el tama√±o del dataset y recursos computacionales.

4. ##### **Curvas de entrenamiento**:

    Monitoriza siempre `loss` y `val_loss` para detectar **sobreajuste**.

5. ##### **Uso de GPU**:

    Esta pr√°ctica es mucho m√°s eficiente con GPU. Si no est√° activa, el tiempo de entrenamiento ser√° mayor.

## ‚úÖ Resumen de la pr√°ctica

En esta pr√°ctica has:

1. Trabajado con un **dataset abierto** (MNIST).
2. Preprocesado y visualizado im√°genes, analizando su distribuci√≥n.
3. Definido un **autoencoder convolucional** en Keras/TensorFlow.
4. Entrenado, validado y graficado curvas de p√©rdida.
5. Evaluado cualitativamente las reconstrucciones (im√°genes).
6. Evaluado cuantitativamente el rendimiento mediante el **MSE**.
7. Extra√≠do representaciones latentes para an√°lisis futuro.


![p2](https://github.com/Grandote58/NeoDeepLab/blob/main/Clase007/assets/pie.png)
